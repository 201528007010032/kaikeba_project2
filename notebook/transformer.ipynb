{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理解语言的 Transformer 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/text/transformer\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />\n",
    "    在 tensorflow.google.cn 上查看</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" />\n",
    "    在 Google Colab 运行</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/transformer.ipynb\">\n",
    "    <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" />\n",
    "    在 Github 上查看源代码</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/text/transformer.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" />下载此 notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 我们的 TensorFlow 社区翻译了这些文档。因为社区翻译是尽力而为， 所以无法保证它们是最准确的，并且反映了最新的\n",
    "[官方英文文档](https://www.tensorflow.org/?hl=en)。如果您有改进此翻译的建议， 请提交 pull request 到\n",
    "[tensorflow/docs](https://github.com/tensorflow/docs) GitHub 仓库。要志愿地撰写或者审核译文，请加入\n",
    "[docs-zh-cn@tensorflow.org Google Group](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-zh-cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程训练了一个 <a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformer 模型</a> 用于将葡萄牙语翻译成英语。这是一个高级示例，假定您具备[文本生成（text generation）](text_generation.ipynb)和 [注意力机制（attention）](nmt_with_attention.ipynb) 的知识。\n",
    "\n",
    "Transformer 模型的核心思想是*自注意力机制（self-attention）*——能注意输入序列的不同位置以计算该序列的表示的能力。Transformer 创建了多层自注意力层（self-attetion layers）组成的堆栈，下文的*按比缩放的点积注意力（Scaled dot product attention）*和*多头注意力（Multi-head attention）*部分对此进行了说明。\n",
    "\n",
    "一个 transformer 模型用自注意力层而非 [RNNs](text_classification_rnn.ipynb) 或 [CNNs](../images/intro_to_cnns.ipynb) 来处理变长的输入。这种通用架构有一系列的优势：\n",
    "\n",
    "* 它不对数据间的时间/空间关系做任何假设。这是处理一组对象（objects）的理想选择（例如，[星际争霸单位（StarCraft units）](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8)）。\n",
    "* 层输出可以并行计算，而非像 RNN 这样的序列计算。\n",
    "* 远距离项可以影响彼此的输出，而无需经过许多 RNN 步骤或卷积层（例如，参见[场景记忆 Transformer（Scene Memory Transformer）](https://arxiv.org/pdf/1903.03878.pdf)）\n",
    "* 它能学习长距离的依赖。在许多序列任务中，这是一项挑战。\n",
    "\n",
    "该架构的缺点是：\n",
    "\n",
    "* 对于时间序列，一个单位时间的输出是从*整个历史记录*计算的，而非仅从输入和当前的隐含状态计算得到。这*可能*效率较低。   \n",
    "* 如果输入*确实*有时间/空间的关系，像文本，则必须加入一些位置编码，否则模型将有效地看到一堆单词。\n",
    "\n",
    "在此 notebook 中训练完模型后，您将能输入葡萄牙语句子，得到其英文翻译。\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# try:\n",
    "#     !pip install tf-nightly \n",
    "# except Exception:\n",
    "#     pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置输入流水线（input pipeline）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 [TFDS](https://tensorflow.google.cn/datasets) 来导入 [葡萄牙语-英语翻译数据集](https://github.com/neulab/word-embeddings-for-nmt)，该数据集来自于 [TED 演讲开放翻译项目](https://www.ted.com/participate/translate).\n",
    "\n",
    "该数据集包含来约 50000 条训练样本，1100 条验证样本，以及 2000 条测试样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate/pt_to_en/1.0.0 (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /Users/xiangyunwu/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c88760b1c834e3b9b23533e73510bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6e155f71624182ad48a822c51a289c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d5e9f6d2dd46e48987762adf0546e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0228d4254a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ted_hrlr_translate/pt_to_en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    338\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    339\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1076\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m   1077\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m     )\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m         prepare_split_kwargs)\n\u001b[1;32m    918\u001b[0m     for split_generator in self._split_generators(\n\u001b[0;32m--> 919\u001b[0;31m         dl_manager, **split_generators_kwargs):\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msplits_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msplit_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/translate/ted_hrlr.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mdl_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DATA_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    413\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_wait_on_promise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_wait_on_promise\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_wait_on_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# type: (Optional[float]) -> T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/promise/promise.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# type: (Optional[float]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(cls, promise, timeout)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# type: (Promise, Optional[float]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0masync_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/promise/async_.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# fulfilled or rejected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrain_queues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/promise/schedulers/immediate.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpromise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_then\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_resolve_or_reject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_resolve_or_reject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mwaited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwaited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timeout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从训练数据集创建自定义子词分词器（subwords tokenizer）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将开始和结束标记（token）添加到输入和目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "          lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "          lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note：为了使本示例较小且相对较快，删除长度大于40个标记的样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.map()` 内部的操作以图模式（graph mode）运行，`.map()` 接收一个不具有 numpy 属性的图张量（graph tensor）。该`分词器（tokenizer）`需要将一个字符串或 Unicode 符号，编码成整数。因此，您需要在 `tf.py_function` 内部运行编码过程，`tf.py_function` 接收一个 eager 张量，该 eager 张量有一个包含字符串值的 numpy 属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "\n",
    "    return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7ba0833cfc04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 将数据集缓存到内存中以加快读取速度。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_examples' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE,padded_shapes=([-1], [-1]))\n",
    "\n",
    "\n",
    "# 流水线技术 重叠训练的预处理和模型训练步骤。当加速器正在执行训练步骤 N 时，CPU 开始准备步骤 N + 1 的数据。这样做可以将步骤时间减少到模型训练与抽取转换数据二者所需的最大时间（而不是二者时间总和）。\n",
    "# 没有流水线技术，CPU 和 GPU/TPU 大部分时间将处于闲置状态:\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE,padded_shapes=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3dd1d7ee3585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置编码（Positional encoding）\n",
    "\n",
    "因为该模型并不包括任何的循环（recurrence）或卷积，所以模型添加了位置编码，为模型提供一些关于单词在句子中相对位置的信息。\n",
    "\n",
    "位置编码向量被加到嵌入（embedding）向量中。嵌入表示一个 d 维空间的标记，在 d 维空间中有着相似含义的标记会离彼此更近。但是，嵌入并没有对在一句话中的词的相对位置进行编码。因此，当加上位置编码后，词将基于*它们含义的相似度以及它们在句子中的位置*，在 d 维空间中离彼此更近。\n",
    "\n",
    "参看 [位置编码](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) 的 notebook 了解更多信息。计算位置编码的公式如下：\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绝对位置：例如每个sequence  , 位置都是从0，1..n开始 \n",
    "- 相对位置：位置的表示是由字与字之间的差表示的。相对位置表达Relative Position Representations (RPR)是Shaw et al., 2018，这个论文指出，同一个sequence中使用相对位置更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 将 cos 应用于数组中的奇数索引；2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遮挡（Masking）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遮挡一批序列中所有的填充标记（pad tokens）。这确保了模型不会将填充作为输入。该 mask 表明填充值 `0` 出现的位置：在这些位置 mask 输出 `1`，否则输出 `0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    tf.linalg.band_part(\n",
    "        input,\n",
    "        num_lower,\n",
    "        num_upper,\n",
    "        name=None\n",
    "    )\n",
    "    input:输入的张量.\n",
    "    num_lower:下三角矩阵保留的副对角线数量，从主对角线开始计算，相当于下三角的带宽。取值为负数时，则全部保留。\n",
    "    num_upper:上三角矩阵保留的副对角线数量，从主对角线开始计算，相当于上三角的带宽。取值为负数时，则全部保留。\n",
    "    \"\"\"\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.4723308  0.02759683 0.7164279 ]], shape=(1, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "print(x)\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/scaled_attention.png\" width=\"400\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Transformer 使用的注意力函数有三个输入：Q（请求（query））、K（主键（key））、V（数值（value））。用于计算注意力权重的等式为：\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "点积注意力被缩小了深度的平方根倍。这样做是因为对于较大的深度值，点积的大小会增大，从而推动 softmax 函数往仅有很小的梯度的方向靠拢，导致了一种很硬的（hard）softmax。\n",
    "\n",
    "例如，假设 `Q` 和 `K` 的均值为0，方差为1。它们的矩阵乘积将有均值为0，方差为 `dk`。因此，*`dk` 的平方根*被用于缩放（而非其他数值），因为，`Q` 和 `K` 的矩阵乘积的均值本应该为 0，方差本应该为1，这样会获得一个更平缓的 softmax。\n",
    "\n",
    "遮挡（mask）与 -1e9（接近于负无穷）相乘。这样做是因为遮挡与缩放的 Q 和 K 的矩阵乘积相加，并在 softmax 之前立即应用。目标是将这些单元归零，因为 softmax 的较大负数输入在输出中接近于零。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- query向量：query顾名思义，是负责寻找这个字的于其他字的相关度（通过其它字的key） \n",
    "- key向量：key向量就是用来于query向量作匹配，得到相关度评分的 \n",
    "- value向量：Value vectors 是实际上的字的表示, 一旦我们得到了字的相关度评分，这些表示是用来加权求和的\n",
    "\n",
    "得到每个字的  之后，我们要得到每个字和句子中其他字的相关关系，我们只需要把这个字的query去和其他字的key作匹配，然后得到分数，最后在通过其它字的value的加权求和（权重就是哪个分数）得到这个字的最终输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"计算注意力权重。\n",
    "    q, k, v 必须具有匹配的前置维度。\n",
    "    k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "    虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "    但是 mask 必须能进行广播转换以便求和。\n",
    "\n",
    "    参数:\n",
    "    q: 请求的形状 == (..., seq_len_q, depth)\n",
    "    k: 主键的形状 == (..., seq_len_k, depth)\n",
    "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "    mask: Float 张量，其形状能转换成\n",
    "          (..., seq_len_q, seq_len_k)。默认为None。\n",
    "\n",
    "    返回值:\n",
    "    输出，注意力权重\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # 缩放 matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 将 mask 加入到缩放的张量上。\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
    "    # 相加等于1。\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "        q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# 这条 `请求（query）符合第二个`主键（key）`，\n",
    "# 因此返回了第二个`数值（value）`。\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合重复出现的主键（第三第四个），\n",
    "# 因此，对所有的相关数值取了平均。\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[10.,  0.,  0.,  0.],\n",
       "       [ 0., 10.,  0.,  0.],\n",
       "       [ 0.,  0., 10., 10.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(temp_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合第一和第二条主键，\n",
    "# 因此，对它们的数值去了平均。\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有请求一起*传递*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多头注意力（Multi-head attention）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/multi_head_attention.png\" width=\"400\" alt=\"multi-head attention\">\n",
    "\n",
    "多头注意力由四部分组成：\n",
    "*    线性层并分拆成多头。\n",
    "*    按比缩放的点积注意力。\n",
    "*    多头及联。\n",
    "*    最后一层线性层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。 \n",
    "\n",
    "将上面定义的 `scaled_dot_product_attention` 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用`tf.transpose` 和 `tf.reshape`），并放入最后的 `Dense` 层。\n",
    "\n",
    "Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        分拆最后一个维度到 (num_heads, depth).\n",
    "        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个 `MultiHeadAttention` 层进行尝试。在序列中的每个位置 `y`，`MultiHeadAttention` 在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点式前馈网络（Point wise feed forward network）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码与解码（Encoder and decoder）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"500\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 模型与标准的[具有注意力机制的序列到序列模型（sequence to sequence with attention model）](nmt_with_attention.ipynb)，遵循相同的一般模式。\n",
    "* 输入语句经过 `N` 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "* 解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器层（Encoder layer）\n",
    "每个编码器层包括以下子层：\n",
    "1.   多头注意力（有填充遮挡）\n",
    "2.   点式前馈网络（Point wise feed forward networks）。\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。Transformer 中有 N 个编码器层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        # (x-mean) / std,\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器层（Decoder layer）\n",
    "\n",
    "每个解码器层包括以下子层：\n",
    "\n",
    "1.   遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "2.   多头注意力（用填充遮挡）。V（数值）和 K（主键）接收*编码器输出*作为输入。Q（请求）接收*遮挡的多头注意力子层的输出*。\n",
    "3.   点式前馈网络\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 `LayerNorm(x + Sublayer(x))`。归一化是在 `d_model`（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflow.google.cn/images/tutorials/transformer/transformer.png\" width=\"500\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        # v, k, q, mask\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, False, None, None)\n",
    "\n",
    "tmp = create_look_ahead_mask(50)\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, False, tmp, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器（Encoder）\n",
    "\n",
    "`编码器` 包括：\n",
    "1.   输入嵌入（Input Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个编码器层（encoder layers）\n",
    "\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。编码器的输出是解码器的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 将嵌入和位置编码相加。\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # 为什么要乘以embedding size的开方？\n",
    "        # 猜测是因为embedding matrix的初始化方式是xavier init，这种方式的方差是1/embedding size，\n",
    "        # 因此乘以embedding size的开方使得embedding matrix的方差是1，在这个scale下可能更有利于embedding matrix的收敛。\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器（Decoder）\n",
    "`解码器`包括：\n",
    "1.   输出嵌入（Output Embedding）\n",
    "2.   位置编码（Positional Encoding）\n",
    "3.   N 个解码器层（decoder layers）\n",
    "\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            # v, k, q\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Transformer\n",
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置超参数（hyperparameters）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器（Optimizer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据[论文](https://arxiv.org/abs/1706.03762)中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数与指标（Loss and metrics）\n",
    "由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与检查点（Training and checkpointing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # 编码器填充遮挡\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第二个注意力模块使用。\n",
    "    # 该填充遮挡用于遮挡编码器的输出。\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解码器的第一个注意力模块使用。\n",
    "    # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_masks(np.array([[1,2,3,0,0]]),np.array([[4,5,6,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"data/checkpoints/transformer/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。`tar_real` 是位移了 1 的同一个输入：在 `tar_inp` 中的每个位置，`tar_real` 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，`sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像[文本生成教程](./text_generation.ipynb)中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，*自注意力（self-attention）*功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n",
    "# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n",
    "# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n",
    "# 更多的通用形状。\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "葡萄牙语作为输入语言，英语为目标语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "  \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估（Evaluate）\n",
    "以下步骤用于评估：\n",
    "\n",
    "* 用葡萄牙语分词器（`tokenizer_pt`）编码输入语句。此外，添加开始和结束标记，这样输入就与模型训练的内容相同。这是编码器输入。\n",
    "* 解码器输入为 `start token == tokenizer_en.vocab_size`。\n",
    "* 计算填充遮挡和前瞻遮挡。\n",
    "* `解码器`通过查看`编码器输出`和它自身的输出（自注意力）给出预测。\n",
    "* 选择最后一个词并计算它的 argmax。\n",
    "* 将预测的词连接到解码器输入，然后传递给解码器。\n",
    "* 在这种方法中，解码器根据它预测的之前的词预测下一个。\n",
    "\n",
    "Note：这里使用的模型具有较小的能力以保持相对较快，因此预测可能不太正确。要复现论文中的结果，请使用全部数据集，并通过修改上述超参数来使用基础 transformer 模型或者 transformer XL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_pt.vocab_size]\n",
    "    end_token = [tokenizer_pt.vocab_size + 1]\n",
    "\n",
    "    # 输入语句是葡萄牙语，增加开始和结束标记\n",
    "    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # 因为目标是英语，输入 transformer 的第一个词应该是\n",
    "    # 英语的开始标记。\n",
    "    decoder_input = [tokenizer_en.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # 从 seq_len 维度选择最后一个词\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 如果 predicted_id 等于结束标记，就返回结果\n",
    "        if predicted_id == tokenizer_en.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_pt.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # 画出注意力权重\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，您已经学习了位置编码，多头注意力，遮挡的重要性以及如何创建一个 transformer。\n",
    "\n",
    "尝试使用一个不同的数据集来训练 transformer。您可也可以通过修改上述的超参数来创建基础 transformer 或者 transformer XL。您也可以使用这里定义的层来创建 [BERT](https://arxiv.org/abs/1810.04805) 并训练最先进的模型。此外，您可以实现 beam search 得到更好的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "https://mp.weixin.qq.com/s/lwAPIdIt98O7EgfMzi4G4Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
